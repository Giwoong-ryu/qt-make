#!/usr/bin/env python3
"""
ì¸ê¸° Pexels í´ë¦½ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

Docker ë¹Œë“œ ì‹œ ì‹¤í–‰ë˜ì–´ ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°°ê²½ í´ë¦½ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

ìš°ì„ ìˆœìœ„:
1. DBì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ í´ë¦½ (clips_metadataì—ì„œ ì¶”ì¶œ)
2. í´ë°±: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ í´ë¦½ ëª©ë¡
"""
import argparse
import json
import logging
import os
import sys
from pathlib import Path
from typing import Optional

import httpx

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ğŸ¬ í´ë°±ìš© ê¸°ë³¸ í´ë¦½ (DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ)
FALLBACK_CLIPS = [
    # ìì—°/í‰í™” í…Œë§ˆ (Pexelsì—ì„œ ì¸ê¸° ìˆëŠ” ë¬´ë£Œ ì˜ìƒ)
    {"id": 3571264, "tags": "mountain landscape"},
    {"id": 2169880, "tags": "ocean waves"},
    {"id": 857251, "tags": "forest trees"},
    {"id": 1409899, "tags": "clouds sky"},
    {"id": 2611250, "tags": "sunset golden"},
    {"id": 3163534, "tags": "nature peaceful"},
    {"id": 5532708, "tags": "valley scenic"},
    {"id": 4509468, "tags": "sunrise morning"},
    {"id": 2491284, "tags": "water reflection"},
    {"id": 3049263, "tags": "serene calm"},
]


def fetch_popular_clips_from_db(limit: int = 50) -> list[dict]:
    """
    Supabase DBì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ ì¸ê¸° í´ë¦½ ì¡°íšŒ

    videos.clips_metadataì—ì„œ pexels_idë¥¼ ì¶”ì¶œí•˜ê³  ì‚¬ìš© ë¹ˆë„ ê³„ì‚°
    """
    try:
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")

        if not supabase_url or not supabase_key:
            logger.warning("[DB] SUPABASE_URL or SUPABASE_KEY not set")
            return []

        from supabase import create_client
        supabase = create_client(supabase_url, supabase_key)

        # clips_metadataê°€ ìˆëŠ” ì™„ë£Œëœ ì˜ìƒë“¤ ì¡°íšŒ
        result = supabase.table("videos") \
            .select("clips_metadata") \
            .eq("status", "completed") \
            .not_.is_("clips_metadata", "null") \
            .order("created_at", desc=True) \
            .limit(200) \
            .execute()

        if not result.data:
            logger.warning("[DB] No completed videos with clips_metadata found")
            return []

        # clips_metadataì—ì„œ pexels_id ì¶”ì¶œ ë° ë¹ˆë„ ê³„ì‚°
        clip_counts = {}  # pexels_id -> count
        clip_urls = {}    # pexels_id -> download_url

        for video in result.data:
            clips_metadata = video.get("clips_metadata", [])
            if not clips_metadata:
                continue

            for clip in clips_metadata:
                pexels_id = clip.get("pexels_id")
                download_url = clip.get("download_url")

                if pexels_id and download_url:
                    clip_counts[pexels_id] = clip_counts.get(pexels_id, 0) + 1
                    clip_urls[pexels_id] = download_url

        if not clip_counts:
            logger.warning("[DB] No pexels_id found in clips_metadata")
            return []

        # ì‚¬ìš© ë¹ˆë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_clips = sorted(clip_counts.items(), key=lambda x: x[1], reverse=True)

        popular_clips = []
        for pexels_id, count in sorted_clips[:limit]:
            popular_clips.append({
                "id": pexels_id,
                "url": clip_urls.get(pexels_id),
                "count": count,
                "tags": f"used_{count}x"
            })

        logger.info(f"[DB] Found {len(popular_clips)} popular clips from DB")
        return popular_clips

    except Exception as e:
        logger.error(f"[DB] Failed to fetch clips from DB: {e}")
        return []


def download_clip_direct(url: str, video_id: int, output_dir: Path, timeout: int = 120) -> bool:
    """
    ì§ì ‘ URLë¡œ í´ë¦½ ë‹¤ìš´ë¡œë“œ (DBì—ì„œ ê°€ì ¸ì˜¨ URL ì‚¬ìš©)
    """
    output_path = output_dir / f"pexels_{video_id}.mp4"

    if output_path.exists():
        logger.info(f"[SKIP] pexels_{video_id}.mp4 already exists")
        return True

    try:
        logger.info(f"[DOWNLOAD] pexels_{video_id}.mp4...")

        with httpx.Client(timeout=timeout) as client:
            response = client.get(url)
            response.raise_for_status()

            with open(output_path, "wb") as f:
                f.write(response.content)

            file_size_mb = output_path.stat().st_size / (1024 * 1024)
            logger.info(f"[OK] pexels_{video_id}.mp4 ({file_size_mb:.1f}MB)")
            return True

    except Exception as e:
        logger.error(f"[ERROR] Download failed for {video_id}: {e}")
        if output_path.exists():
            output_path.unlink()
        return False


def download_clip_via_api(video_id: int, output_dir: Path, tags: str, timeout: int = 120) -> bool:
    """
    Pexels APIë¡œ í´ë¦½ ì •ë³´ ì¡°íšŒ í›„ ë‹¤ìš´ë¡œë“œ (í´ë°±ìš©)
    """
    output_path = output_dir / f"pexels_{video_id}.mp4"

    if output_path.exists():
        logger.info(f"[SKIP] pexels_{video_id}.mp4 already exists")
        return True

    try:
        pexels_api_key = os.getenv("PEXELS_API_KEY")
        if not pexels_api_key:
            logger.warning(f"[SKIP] PEXELS_API_KEY not set")
            return False

        api_url = f"https://api.pexels.com/videos/videos/{video_id}"
        headers = {"Authorization": pexels_api_key}

        with httpx.Client(timeout=timeout) as client:
            # ì˜ìƒ ì •ë³´ ì¡°íšŒ
            response = client.get(api_url, headers=headers)
            response.raise_for_status()
            video_data = response.json()

            # HD í™”ì§ˆ URL ì°¾ê¸°
            video_files = video_data.get("video_files", [])
            download_url = None

            for vf in video_files:
                if vf.get("width") == 1920 and vf.get("height") == 1080:
                    download_url = vf.get("link")
                    break

            if not download_url and video_files:
                video_files_sorted = sorted(
                    video_files,
                    key=lambda x: x.get("width", 0) * x.get("height", 0),
                    reverse=True
                )
                download_url = video_files_sorted[0].get("link")

            if not download_url:
                logger.error(f"[ERROR] No download URL for {video_id}")
                return False

            # ë‹¤ìš´ë¡œë“œ
            logger.info(f"[DOWNLOAD] pexels_{video_id}.mp4 ({tags})...")
            video_response = client.get(download_url)
            video_response.raise_for_status()

            with open(output_path, "wb") as f:
                f.write(video_response.content)

            file_size_mb = output_path.stat().st_size / (1024 * 1024)
            logger.info(f"[OK] pexels_{video_id}.mp4 ({file_size_mb:.1f}MB)")
            return True

    except Exception as e:
        logger.error(f"[ERROR] API download failed for {video_id}: {e}")
        if output_path.exists():
            output_path.unlink()
        return False


def main():
    parser = argparse.ArgumentParser(description="Download popular Pexels clips")
    parser.add_argument("--count", type=int, default=50, help="Number of clips to download")
    parser.add_argument("--output", type=str, default="/app/background_clips", help="Output directory")
    parser.add_argument("--timeout", type=int, default=120, help="Download timeout (seconds)")
    parser.add_argument("--fallback-only", action="store_true", help="Skip DB, use fallback clips only")
    args = parser.parse_args()

    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info(f"=" * 60)
    logger.info(f"Clip Caching System - Starting")
    logger.info(f"  Output: {output_dir}")
    logger.info(f"  Target: {args.count} clips")
    logger.info(f"=" * 60)

    clips_to_download = []
    source = "unknown"

    # 1. DBì—ì„œ ì¸ê¸° í´ë¦½ ì¡°íšŒ ì‹œë„
    if not args.fallback_only:
        logger.info("\n[Step 1] Fetching popular clips from DB...")
        db_clips = fetch_popular_clips_from_db(args.count)

        if db_clips:
            clips_to_download = db_clips
            source = "database"
            logger.info(f"[OK] Using {len(db_clips)} clips from DB (actual usage data)")

    # 2. DB ì‹¤íŒ¨ ì‹œ í´ë°±
    if not clips_to_download:
        logger.info("\n[Step 2] Using fallback clip list...")
        clips_to_download = FALLBACK_CLIPS[:args.count]
        source = "fallback"
        logger.info(f"[OK] Using {len(clips_to_download)} fallback clips")

    # 3. ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
    logger.info(f"\n[Step 3] Downloading {len(clips_to_download)} clips...")

    success_count = 0
    fail_count = 0

    for idx, clip in enumerate(clips_to_download, 1):
        video_id = clip["id"]
        logger.info(f"\n[{idx}/{len(clips_to_download)}] pexels_{video_id}...")

        # DBì—ì„œ ê°€ì ¸ì˜¨ ê²½ìš° ì§ì ‘ URL ì‚¬ìš©
        if source == "database" and clip.get("url"):
            success = download_clip_direct(
                clip["url"], video_id, output_dir, args.timeout
            )
        else:
            # í´ë°±: Pexels API ì‚¬ìš©
            success = download_clip_via_api(
                video_id, output_dir, clip.get("tags", ""), args.timeout
            )

        if success:
            success_count += 1
        else:
            fail_count += 1

    # 4. ê²°ê³¼ ìš”ì•½
    logger.info(f"\n{'=' * 60}")
    logger.info(f"Download Complete!")
    logger.info(f"  Source: {source}")
    logger.info(f"  Success: {success_count}")
    logger.info(f"  Failed: {fail_count}")
    logger.info(f"  Cache Hit Rate (expected): {success_count}/{args.count} = {success_count/args.count*100:.0f}%")
    logger.info(f"{'=' * 60}")

    # 5. ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        "source": source,
        "clips": [
            {"id": c["id"], "count": c.get("count", 0)}
            for c in clips_to_download
        ],
        "downloaded": success_count,
        "failed": fail_count,
        "output_dir": str(output_dir)
    }

    metadata_path = output_dir / "clips_metadata.json"
    with open(metadata_path, "w") as f:
        json.dump(metadata, f, indent=2)

    logger.info(f"Metadata saved: {metadata_path}")

    sys.exit(0)


if __name__ == "__main__":
    main()
